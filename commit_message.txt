Ramin Yazdani | ML Model Selection Notebook | main | feat(cv): Implement custom K-fold cross-validation

Implement K-fold cross-validation from scratch to demonstrate understanding of fundamental model evaluation concepts.

This commit adds:
- Custom kfold_cross_validation function with manual data splitting
- Train/test split logic for K folds
- Accuracy and F1 score computation
- Reusable evaluation framework for all subsequent models

The implementation is educational rather than using sklearn's built-in CV:
- Shows the algorithm step-by-step
- Demonstrates understanding of the underlying mechanics
- Creates indices for train/test splits manually
- Computes performance metrics explicitly

Key features of the implementation:
- Takes any sklearn-compatible model
- Supports configurable K value
- Returns mean accuracy and F1 score
- Properly handles data indexing for each fold

This is a critical foundation for all model comparison work that follows. Understanding cross-validation by building it from scratch is more valuable for demonstration purposes than using a black-box library function.

Files modified:
- ml_model_selection_analysis.ipynb - Extended to cells 0-9

Verification: Tested the custom CV function with a simple model. Confirmed it produces reasonable results and properly splits data into K folds. All metrics compute correctly.