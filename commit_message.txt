Ramin Yazdani | ML Model Selection Notebook | main | feat(viz): Add decision boundary visualization for classifiers

Implement comprehensive decision boundary visualization to show how each model separates classes in 2D space.

This commit adds:
- Decision boundary plotting utility function
- Side-by-side visualizations for Logistic Regression, LDA, and QDA
- Color-coded decision regions
- Training data overlay on decision boundaries
- Analysis comparing linear vs. quadratic boundaries

The visualizations reveal:
- Logistic Regression: Linear boundary, struggles with circular data
- LDA: Also linear boundary, similar limitations
- QDA: Quadratic boundary, perfectly suited for concentric circles

Visual insights that metrics alone cannot provide:
- Why QDA outperforms linear models on this data
- How decision boundaries relate to data distribution
- The fundamental difference between linear and quadratic classifiers
- Where each model makes correct vs. incorrect predictions

Decision boundary visualization is crucial for:
- Understanding model behavior beyond accuracy numbers
- Explaining why certain models work better for specific data patterns
- Demonstrating the importance of matching model complexity to data structure
- Portfolio demonstration of data visualization skills

Files modified:
- ml_model_selection_analysis.ipynb - Extended to cells 0-21

Verification: Decision boundary plots render correctly for all three models. QDA shows circular boundary matching the data structure. Linear models show straight boundaries as expected. Visualization clearly demonstrates why QDA is superior for this dataset.